#! https://zhuanlan.zhihu.com/p/424465919
# 偏差和方差杂谈

## 基本假设

我们假设一个数据集满足$y=f(x)+\varepsilon$，取自联合概率密度函数$p(x,y)$。x为特征，y为标签，$\varepsilon$是期望为0的随机扰动项，一般可设其满足$N(0,1)$。

### 偏差和方差

我们把该数据集分成K份训练集和一份验证集(交叉验证的方式)，用各训练集分别训练得到K个模型，再用这K个模型分别运行验证集(含N个样本)，得到K份预测值记为$\hat{y}_{ij}$，真实值记为$y_j$,其中$i=1,2...K,j=1,2...N$

- $\operatorname{Bias}(\hat{y})=\frac{1}{N}\sum_j^N{[(\frac{1}{K}\sum_i^K \hat{y}_{ij})-y_j]}$，也就是不同模型对于同一测试集样本预测结果的均值和真实值之间的差距。
- $\operatorname{Var}(\hat{y})=\frac{1}{N}\sum_j^N{[\frac{1}{K}\sum_i^K{(\hat{y}_{ij}-\bar{y}_j)^2}]}$，$\bar{y}_j$代表不同模型预测的均值，度量的是对于同一样本，模型预测结果的离散程度。

注意，此处得到的结果均为对理论偏差和方差的估计

#### 图形化解释偏差和方差

这张被用烂的靶心图对偏差和方差的展现非常直观，不再过多解释
![靶心图](resources/640.webp)

### (均方)误差

对于一份样本，记某个模型的预测值为$\hat{y}$，其均方误差(Mean Squared Error，记为MSE)可分解为偏差平方、方差和扰动项方差之和：
$$
\begin{aligned}
\operatorname{MSE}(\hat{y}) &=\mathrm{E}[y-\hat{y}]^{2} \\
&=\mathrm{E}[f(x)+\varepsilon-\hat{y})]^{2} \quad(\text { 代入模型 } y=f(x)+\varepsilon) \\
&=\mathrm{E}[(f(x)-\mathrm{E} \hat{y})+\mathrm{E}  \hat{y}- \hat{y}+\varepsilon]^{2} \\
&=\underbrace{[\mathrm{E}  \hat{y}-f( x)]^{2}}_{\text {Bias }^{2}}+\underbrace{\mathrm{E}[ \hat{y}-\mathrm{E}  \hat{y}]^{2}}_{\text {Variance }}+\underbrace{\mathrm{E}\left(\varepsilon^{2}\right)}_{\operatorname{Var}(\varepsilon)} \\
\end{aligned}
$$

其中，偏差平方与方差均“可降低”(reducible)，而$\varepsilon$无法被降低(irreducible)
模型的训练误差是指该模型在训练集上的误差，验证误差(也叫泛化误差)则是指在不参与训练的验证集上的误差，它们与偏差方差有着更加深入的关系

### 训练误差、验证误差与偏差、方差的关系

在训练过程中，通过训练误差和验证误差可以判断偏差和方差的情况

- 若训练误差较高，一般验证误差也较高。此时模型过于简单而甚至都难以拟合训练集(欠拟合underfitting)，更不用说拟合验证集。体现在测试集上就是高方差高偏差的情况。
- 若训练误差低到了一定程度，也是对一个模型的最低要求。此时如果验证误差较高，那么说明我们过度拟合了训练集(过拟合overfitting)，是高方差的情况。如果训练集和验证集同分布且充分打乱的话，此时偏差应当较低。
- 在第一种情况下，如果此时验证误差相对于训练误差甚至还要高很多，那么同样符合第二种情况(不过都已经欠拟合了，就不叫它过拟合了)，此时就是高方差高偏差；与此类似，如果此时验证误差和训练误差差不多，那么就是高偏差低方差的情况(可以想象打靶的时候全都稳定打在1环)
- 最理想的情况，就是训练误差低到一定程度的同时，我们通过一系列手段使得验证误差同样较低，此时也就是低偏差低方差的情况，是我们追求的目标
  
应当注意的是，如果训练集和验证集不同分布，上述的结论很有可能不成立。直观的想法是因为这样用训练集训练出来的模型拥有的经验很难说可以用在验证集上，训练误差和验证误差并无关联，也就很难说和用验证集计算的偏差方差有什么关系了。

### 模型复杂度和误差的关系

通过上面的推导我们可以很容易得出，当我们逐渐加大模型的复杂程度时，训练误差都是呈现出图中逐渐下降后稳定的样子，验证集理论上将会出现U型曲线：

- 模型复杂度低(比如就一层线性连接)模型欠拟合，难以拟合训练集，自然无法拟合验证集，偏差较高，验证误差较高
- 模型复杂度提高到一定程度(可能多了几层网络)，模型对于训练集的拟合程度较好，偏差下降，验证集误差降低
- 模型复杂度继续提高(网络深度极高)，此时模型仍然拟合训练集但也进无可进(偏差不再下降)，但过度关注到训练集特有的特征，产生过拟合，泛化能力下降，使得方差上升，验证集误差上升
![训练验证](resources/train_valid.jpg)

验证误差具体情况如下图所示
![偏差和误差](resources/bias.png)

因此，在选择模型复杂程度时，存在偏差与方差的权衡(bias-variance trade-off)，须选择合适的模型复杂程度，使得模型的均方误差达到最小值。

然而，如果任何复杂度的模型都难以达到方差较低的情况又应该怎么办呢？
解决办法包括使用更多的数据以及正则化。
